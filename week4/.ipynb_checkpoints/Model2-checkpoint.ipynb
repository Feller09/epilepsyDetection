{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bored-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from keras.models import Sequential \n",
    "from keras.utils import np_utils \n",
    "from keras.layers import Dense,Activation,LSTM,Dropout,AveragePooling3D \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "painted-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  \\\n",
      "0      X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   \n",
      "1      X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   \n",
      "2         X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57   \n",
      "3       X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   \n",
      "4       X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4   \n",
      "...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
      "11495  X22.V1.114  -22  -22  -23  -26  -36  -42  -45  -42  -45  ...    15   \n",
      "11496  X19.V1.354  -47  -11   28   77  141  211  246  240  193  ...   -65   \n",
      "11497    X8.V1.28   14    6  -13  -16   10   26   27   -9    4  ...   -65   \n",
      "11498  X10.V1.932  -40  -25   -9  -12   -2   12    7   19   22  ...   121   \n",
      "11499  X16.V1.210   29   41   57   72   74   62   54   43   31  ...   -59   \n",
      "\n",
      "       X171  X172  X173  X174  X175  X176  X177  X178  y  \n",
      "0       -15   -31   -77  -103  -127  -116   -83   -51  4  \n",
      "1       150   146   152   157   156   154   143   129  1  \n",
      "2        64    48    19   -12   -30   -35   -35   -36  5  \n",
      "3       -81   -80   -77   -85   -77   -72   -69   -65  5  \n",
      "4         2   -12   -32   -41   -65   -83   -89   -73  5  \n",
      "...     ...   ...   ...   ...   ...   ...   ...   ... ..  \n",
      "11495    16    12     5    -1   -18   -37   -47   -48  2  \n",
      "11496   -33    -7    14    27    48    77   117   170  1  \n",
      "11497   -48   -61   -62   -67   -30    -2    -1    -8  5  \n",
      "11498   135   148   143   116    86    68    59    55  3  \n",
      "11499   -25    -4     2     5     4    -2     2    20  4  \n",
      "\n",
      "[11500 rows x 180 columns]\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('data.csv')\n",
    "df.head()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superior-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.values \n",
    "x=x[:,1:-1]\n",
    "x = np.asarray(x).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dimensional-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11500, 6)\n",
      "(11500, 178)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "##taking 20% for test ## replace x with y as it will half for testing and half for training for ybased \n",
    "y=np.array(df['y'])\n",
    "y=np_utils.to_categorical(y)\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.20,random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "precise-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 256)               11776     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 74,613\n",
      "Trainable params: 74,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##old model using the relu\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(256,input_shape=(45,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fresh-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "contemporary-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "920/920 - 3s - loss: 0.4006 - accuracy: 0.4239 - val_loss: 0.3740 - val_accuracy: 0.4470\n",
      "Epoch 2/60\n",
      "920/920 - 3s - loss: 0.3668 - accuracy: 0.4824 - val_loss: 0.3739 - val_accuracy: 0.4496\n",
      "Epoch 3/60\n",
      "920/920 - 3s - loss: 0.3525 - accuracy: 0.5241 - val_loss: 0.3878 - val_accuracy: 0.5052\n",
      "Epoch 4/60\n",
      "920/920 - 3s - loss: 0.3302 - accuracy: 0.5676 - val_loss: 0.3285 - val_accuracy: 0.5743\n",
      "Epoch 5/60\n",
      "920/920 - 3s - loss: 0.3141 - accuracy: 0.6016 - val_loss: 0.3136 - val_accuracy: 0.6070\n",
      "Epoch 6/60\n",
      "920/920 - 3s - loss: 0.2946 - accuracy: 0.6255 - val_loss: 0.3226 - val_accuracy: 0.5965\n",
      "Epoch 7/60\n",
      "920/920 - 3s - loss: 0.3025 - accuracy: 0.6170 - val_loss: 0.3113 - val_accuracy: 0.5943\n",
      "Epoch 8/60\n",
      "920/920 - 3s - loss: 0.2960 - accuracy: 0.6175 - val_loss: 0.3033 - val_accuracy: 0.6096\n",
      "Epoch 9/60\n",
      "920/920 - 3s - loss: 0.2942 - accuracy: 0.6196 - val_loss: 0.3735 - val_accuracy: 0.5583\n",
      "Epoch 10/60\n",
      "920/920 - 3s - loss: 0.2924 - accuracy: 0.6357 - val_loss: 0.3019 - val_accuracy: 0.6239\n",
      "Epoch 11/60\n",
      "920/920 - 3s - loss: 0.4509 - accuracy: 0.4912 - val_loss: 0.4809 - val_accuracy: 0.2809\n",
      "Epoch 12/60\n",
      "920/920 - 3s - loss: 0.3693 - accuracy: 0.5075 - val_loss: 0.3539 - val_accuracy: 0.5496\n",
      "Epoch 13/60\n",
      "920/920 - 3s - loss: 0.3413 - accuracy: 0.5752 - val_loss: 0.3432 - val_accuracy: 0.5774\n",
      "Epoch 14/60\n",
      "920/920 - 3s - loss: 0.3188 - accuracy: 0.6049 - val_loss: 0.3391 - val_accuracy: 0.5743\n",
      "Epoch 15/60\n",
      "920/920 - 3s - loss: 0.2927 - accuracy: 0.6408 - val_loss: 0.3271 - val_accuracy: 0.5917\n",
      "Epoch 16/60\n",
      "920/920 - 3s - loss: 0.3050 - accuracy: 0.6235 - val_loss: 0.3164 - val_accuracy: 0.6065\n",
      "Epoch 17/60\n",
      "920/920 - 3s - loss: 0.2952 - accuracy: 0.6254 - val_loss: 0.3363 - val_accuracy: 0.5774\n",
      "Epoch 18/60\n",
      "920/920 - 3s - loss: 0.2935 - accuracy: 0.6317 - val_loss: 0.3173 - val_accuracy: 0.6191\n",
      "Epoch 19/60\n",
      "920/920 - 3s - loss: 0.2974 - accuracy: 0.6267 - val_loss: 0.3248 - val_accuracy: 0.5887\n",
      "Epoch 20/60\n",
      "920/920 - 3s - loss: 0.2994 - accuracy: 0.6203 - val_loss: 0.3345 - val_accuracy: 0.5696\n",
      "Epoch 21/60\n",
      "920/920 - 3s - loss: 0.3110 - accuracy: 0.6074 - val_loss: 0.3584 - val_accuracy: 0.5313\n",
      "Epoch 22/60\n",
      "920/920 - 3s - loss: 0.3320 - accuracy: 0.5627 - val_loss: 0.3388 - val_accuracy: 0.5413\n",
      "Epoch 23/60\n",
      "920/920 - 3s - loss: 0.3387 - accuracy: 0.5343 - val_loss: 0.3530 - val_accuracy: 0.4817\n",
      "Epoch 24/60\n",
      "920/920 - 3s - loss: 0.3332 - accuracy: 0.5351 - val_loss: 0.3398 - val_accuracy: 0.5357\n",
      "Epoch 25/60\n",
      "920/920 - 3s - loss: 0.3199 - accuracy: 0.5624 - val_loss: 0.3403 - val_accuracy: 0.5530\n",
      "Epoch 26/60\n",
      "920/920 - 3s - loss: 0.3278 - accuracy: 0.5415 - val_loss: 0.3316 - val_accuracy: 0.5322\n",
      "Epoch 27/60\n",
      "920/920 - 3s - loss: 0.3275 - accuracy: 0.5491 - val_loss: 0.3371 - val_accuracy: 0.5426\n",
      "Epoch 28/60\n",
      "920/920 - 3s - loss: 0.3161 - accuracy: 0.5613 - val_loss: 0.3380 - val_accuracy: 0.5365\n",
      "Epoch 29/60\n",
      "920/920 - 3s - loss: 0.3022 - accuracy: 0.5768 - val_loss: 0.3150 - val_accuracy: 0.5826\n",
      "Epoch 30/60\n",
      "920/920 - 3s - loss: 0.2947 - accuracy: 0.6000 - val_loss: 0.3083 - val_accuracy: 0.5987\n",
      "Epoch 31/60\n",
      "920/920 - 3s - loss: 0.2800 - accuracy: 0.6277 - val_loss: 0.3123 - val_accuracy: 0.6057\n",
      "Epoch 32/60\n",
      "920/920 - 3s - loss: 0.2625 - accuracy: 0.6589 - val_loss: 0.2964 - val_accuracy: 0.6009\n",
      "Epoch 33/60\n",
      "920/920 - 3s - loss: 0.2756 - accuracy: 0.6107 - val_loss: 0.3726 - val_accuracy: 0.5704\n",
      "Epoch 34/60\n",
      "920/920 - 3s - loss: 0.2690 - accuracy: 0.6277 - val_loss: 0.3329 - val_accuracy: 0.5809\n",
      "Epoch 35/60\n",
      "920/920 - 3s - loss: 0.2760 - accuracy: 0.5920 - val_loss: 0.3133 - val_accuracy: 0.5252\n",
      "Epoch 36/60\n",
      "920/920 - 3s - loss: 0.2966 - accuracy: 0.5597 - val_loss: 0.3950 - val_accuracy: 0.4939\n",
      "Epoch 37/60\n",
      "920/920 - 3s - loss: 0.3086 - accuracy: 0.5375 - val_loss: 0.3958 - val_accuracy: 0.5030\n",
      "Epoch 38/60\n",
      "920/920 - 3s - loss: 0.3090 - accuracy: 0.5467 - val_loss: 0.3292 - val_accuracy: 0.5261\n",
      "Epoch 39/60\n",
      "920/920 - 3s - loss: 0.2984 - accuracy: 0.5500 - val_loss: 0.3478 - val_accuracy: 0.5183\n",
      "Epoch 40/60\n",
      "920/920 - 3s - loss: 0.3210 - accuracy: 0.5095 - val_loss: 0.3632 - val_accuracy: 0.4891\n",
      "Epoch 41/60\n",
      "920/920 - 3s - loss: 0.3302 - accuracy: 0.5055 - val_loss: 0.3866 - val_accuracy: 0.4774\n",
      "Epoch 42/60\n",
      "920/920 - 3s - loss: 0.3293 - accuracy: 0.5064 - val_loss: 0.3560 - val_accuracy: 0.4726\n",
      "Epoch 43/60\n",
      "920/920 - 3s - loss: 0.4039 - accuracy: 0.3804 - val_loss: 0.5017 - val_accuracy: 0.2074\n",
      "Epoch 44/60\n",
      "920/920 - 3s - loss: 0.5022 - accuracy: 0.1940 - val_loss: 0.5012 - val_accuracy: 0.2065\n",
      "Epoch 45/60\n",
      "920/920 - 3s - loss: 0.5019 - accuracy: 0.2020 - val_loss: 0.5010 - val_accuracy: 0.2065\n",
      "Epoch 46/60\n",
      "920/920 - 3s - loss: 0.5020 - accuracy: 0.1926 - val_loss: 0.5002 - val_accuracy: 0.2065\n",
      "Epoch 47/60\n",
      "920/920 - 3s - loss: 0.5018 - accuracy: 0.1936 - val_loss: 0.5008 - val_accuracy: 0.2065\n",
      "Epoch 48/60\n",
      "920/920 - 3s - loss: 0.5017 - accuracy: 0.1980 - val_loss: 0.5054 - val_accuracy: 0.1835\n",
      "Epoch 49/60\n",
      "920/920 - 3s - loss: 0.5018 - accuracy: 0.1975 - val_loss: 0.5004 - val_accuracy: 0.2065\n",
      "Epoch 50/60\n",
      "920/920 - 3s - loss: 0.5015 - accuracy: 0.2043 - val_loss: 0.5013 - val_accuracy: 0.2065\n",
      "Epoch 51/60\n",
      "920/920 - 3s - loss: 0.5016 - accuracy: 0.1951 - val_loss: 0.5012 - val_accuracy: 0.2052\n",
      "Epoch 52/60\n",
      "920/920 - 3s - loss: 0.5017 - accuracy: 0.1938 - val_loss: 0.5013 - val_accuracy: 0.1835\n",
      "Epoch 53/60\n",
      "920/920 - 3s - loss: 0.5014 - accuracy: 0.2076 - val_loss: 0.5009 - val_accuracy: 0.1974\n",
      "Epoch 54/60\n",
      "920/920 - 3s - loss: 0.5013 - accuracy: 0.2001 - val_loss: 0.5012 - val_accuracy: 0.1974\n",
      "Epoch 55/60\n",
      "920/920 - 3s - loss: 0.5015 - accuracy: 0.1955 - val_loss: 0.5006 - val_accuracy: 0.2065\n",
      "Epoch 56/60\n",
      "920/920 - 3s - loss: 0.5014 - accuracy: 0.1942 - val_loss: 0.5023 - val_accuracy: 0.1974\n",
      "Epoch 57/60\n",
      "920/920 - 3s - loss: 0.5010 - accuracy: 0.2018 - val_loss: 0.5005 - val_accuracy: 0.2065\n",
      "Epoch 58/60\n",
      "920/920 - 3s - loss: 0.5014 - accuracy: 0.1963 - val_loss: 0.5012 - val_accuracy: 0.1835\n",
      "Epoch 59/60\n",
      "920/920 - 3s - loss: 0.5014 - accuracy: 0.1974 - val_loss: 0.5013 - val_accuracy: 0.1835\n",
      "Epoch 60/60\n",
      "920/920 - 3s - loss: 0.5012 - accuracy: 0.2020 - val_loss: 0.5007 - val_accuracy: 0.2074\n"
     ]
    }
   ],
   "source": [
    "##batch size : 10 ,epochs : 60\n",
    "hist = model.fit(((x_train[:,::4]-x_train.mean())/x_train.std()),y_train[:,1:],10,60,verbose=2,validation_data=((x_test[:,::4]-x_test.mean())/x_test.std(),y_test[:,1:]),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sacred-flush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 256)               11776     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 74,613\n",
      "Trainable params: 74,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##new model using the sigmoid\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(256,input_shape=(45,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "velvet-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "posted-english",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "920/920 - 3s - loss: 0.5012 - accuracy: 0.2007 - val_loss: 0.5012 - val_accuracy: 0.1835\n",
      "Epoch 2/60\n",
      "920/920 - 3s - loss: 0.5011 - accuracy: 0.2013 - val_loss: 0.5004 - val_accuracy: 0.2065\n",
      "Epoch 3/60\n",
      "920/920 - 3s - loss: 0.5012 - accuracy: 0.1990 - val_loss: 0.5005 - val_accuracy: 0.2052\n",
      "Epoch 4/60\n",
      "920/920 - 3s - loss: 0.5013 - accuracy: 0.1928 - val_loss: 0.5015 - val_accuracy: 0.1835\n",
      "Epoch 5/60\n",
      "920/920 - 3s - loss: 0.5011 - accuracy: 0.2010 - val_loss: 0.5022 - val_accuracy: 0.1835\n",
      "Epoch 6/60\n",
      "920/920 - 3s - loss: 0.5011 - accuracy: 0.2032 - val_loss: 0.5009 - val_accuracy: 0.2065\n",
      "Epoch 7/60\n",
      "920/920 - 3s - loss: 0.5009 - accuracy: 0.1968 - val_loss: 0.5006 - val_accuracy: 0.2065\n",
      "Epoch 8/60\n",
      "920/920 - 3s - loss: 0.5013 - accuracy: 0.1985 - val_loss: 0.5011 - val_accuracy: 0.1835\n",
      "Epoch 9/60\n",
      "920/920 - 3s - loss: 0.5010 - accuracy: 0.1957 - val_loss: 0.5004 - val_accuracy: 0.2074\n",
      "Epoch 10/60\n",
      "920/920 - 3s - loss: 0.5009 - accuracy: 0.2026 - val_loss: 0.5003 - val_accuracy: 0.2052\n",
      "Epoch 11/60\n",
      "920/920 - 3s - loss: 0.5011 - accuracy: 0.2011 - val_loss: 0.5009 - val_accuracy: 0.1974\n",
      "Epoch 12/60\n",
      "920/920 - 3s - loss: 0.5012 - accuracy: 0.1984 - val_loss: 0.5007 - val_accuracy: 0.1974\n",
      "Epoch 13/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.2067 - val_loss: 0.5010 - val_accuracy: 0.2052\n",
      "Epoch 14/60\n",
      "920/920 - 3s - loss: 0.5011 - accuracy: 0.1977 - val_loss: 0.5009 - val_accuracy: 0.1835\n",
      "Epoch 15/60\n",
      "920/920 - 3s - loss: 0.5009 - accuracy: 0.2007 - val_loss: 0.5019 - val_accuracy: 0.1974\n",
      "Epoch 16/60\n",
      "920/920 - 3s - loss: 0.5009 - accuracy: 0.2025 - val_loss: 0.5015 - val_accuracy: 0.1835\n",
      "Epoch 17/60\n",
      "920/920 - 3s - loss: 0.5010 - accuracy: 0.1998 - val_loss: 0.5010 - val_accuracy: 0.1835\n",
      "Epoch 18/60\n",
      "920/920 - 3s - loss: 0.5010 - accuracy: 0.1980 - val_loss: 0.5020 - val_accuracy: 0.1835\n",
      "Epoch 19/60\n",
      "920/920 - 3s - loss: 0.5010 - accuracy: 0.1922 - val_loss: 0.5004 - val_accuracy: 0.2052\n",
      "Epoch 20/60\n",
      "920/920 - 3s - loss: 0.5010 - accuracy: 0.1926 - val_loss: 0.5005 - val_accuracy: 0.2065\n",
      "Epoch 21/60\n",
      "920/920 - 3s - loss: 0.5009 - accuracy: 0.1954 - val_loss: 0.5003 - val_accuracy: 0.2052\n",
      "Epoch 22/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1997 - val_loss: 0.5005 - val_accuracy: 0.1974\n",
      "Epoch 23/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2008 - val_loss: 0.5003 - val_accuracy: 0.2074\n",
      "Epoch 24/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1967 - val_loss: 0.5009 - val_accuracy: 0.1974\n",
      "Epoch 25/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1934 - val_loss: 0.5010 - val_accuracy: 0.1835\n",
      "Epoch 26/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1995 - val_loss: 0.5010 - val_accuracy: 0.1835\n",
      "Epoch 27/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1992 - val_loss: 0.5009 - val_accuracy: 0.1974\n",
      "Epoch 28/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2010 - val_loss: 0.5013 - val_accuracy: 0.1835\n",
      "Epoch 29/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2012 - val_loss: 0.5007 - val_accuracy: 0.1974\n",
      "Epoch 30/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1971 - val_loss: 0.5018 - val_accuracy: 0.1835\n",
      "Epoch 31/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1997 - val_loss: 0.5004 - val_accuracy: 0.2065\n",
      "Epoch 32/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1967 - val_loss: 0.5015 - val_accuracy: 0.1835\n",
      "Epoch 33/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1986 - val_loss: 0.5007 - val_accuracy: 0.2065\n",
      "Epoch 34/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1995 - val_loss: 0.5007 - val_accuracy: 0.1974\n",
      "Epoch 35/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1960 - val_loss: 0.5004 - val_accuracy: 0.1974\n",
      "Epoch 36/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1957 - val_loss: 0.5007 - val_accuracy: 0.2052\n",
      "Epoch 37/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1910 - val_loss: 0.5005 - val_accuracy: 0.1835\n",
      "Epoch 38/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1978 - val_loss: 0.5003 - val_accuracy: 0.2052\n",
      "Epoch 39/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2015 - val_loss: 0.5007 - val_accuracy: 0.1974\n",
      "Epoch 40/60\n",
      "920/920 - 3s - loss: 0.5006 - accuracy: 0.2036 - val_loss: 0.5003 - val_accuracy: 0.2074\n",
      "Epoch 41/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2032 - val_loss: 0.5016 - val_accuracy: 0.1835\n",
      "Epoch 42/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.2002 - val_loss: 0.5012 - val_accuracy: 0.1835\n",
      "Epoch 43/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1995 - val_loss: 0.5007 - val_accuracy: 0.2052\n",
      "Epoch 44/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2026 - val_loss: 0.5007 - val_accuracy: 0.1974\n",
      "Epoch 45/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2016 - val_loss: 0.5004 - val_accuracy: 0.2052\n",
      "Epoch 46/60\n",
      "920/920 - 3s - loss: 0.5009 - accuracy: 0.1917 - val_loss: 0.5010 - val_accuracy: 0.1974\n",
      "Epoch 47/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.2033 - val_loss: 0.5008 - val_accuracy: 0.2065\n",
      "Epoch 48/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.2009 - val_loss: 0.5005 - val_accuracy: 0.2065\n",
      "Epoch 49/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2024 - val_loss: 0.5008 - val_accuracy: 0.1835\n",
      "Epoch 50/60\n",
      "920/920 - 3s - loss: 0.5006 - accuracy: 0.2048 - val_loss: 0.5005 - val_accuracy: 0.2065\n",
      "Epoch 51/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1962 - val_loss: 0.5003 - val_accuracy: 0.2065\n",
      "Epoch 52/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1968 - val_loss: 0.5004 - val_accuracy: 0.2074\n",
      "Epoch 53/60\n",
      "920/920 - 3s - loss: 0.5006 - accuracy: 0.2034 - val_loss: 0.5012 - val_accuracy: 0.1835\n",
      "Epoch 54/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1930 - val_loss: 0.5012 - val_accuracy: 0.1835\n",
      "Epoch 55/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.2017 - val_loss: 0.5007 - val_accuracy: 0.2065\n",
      "Epoch 56/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1941 - val_loss: 0.5007 - val_accuracy: 0.1835\n",
      "Epoch 57/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1971 - val_loss: 0.5008 - val_accuracy: 0.2052\n",
      "Epoch 58/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1964 - val_loss: 0.5006 - val_accuracy: 0.2065\n",
      "Epoch 59/60\n",
      "920/920 - 3s - loss: 0.5008 - accuracy: 0.1917 - val_loss: 0.5009 - val_accuracy: 0.2074\n",
      "Epoch 60/60\n",
      "920/920 - 3s - loss: 0.5007 - accuracy: 0.1982 - val_loss: 0.5015 - val_accuracy: 0.2052\n"
     ]
    }
   ],
   "source": [
    "hist2 = model.fit(((x_train[:,::4]-x_train.mean())/x_train.std()),y_train[:,1:],10,60,verbose=2,validation_data=((x_test[:,::4]-x_test.mean())/x_test.std(),y_test[:,1:]),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fresh-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9200, 178, 1)\n",
      "(2300, 178, 1)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 45, 56)            12992     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 45, 56)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 56)                25312     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 20)                1140      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 126       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 39,570\n",
      "Trainable params: 39,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##some conversion before using the lstm model to change the input tensor dimension \n",
    "x_train = x_train.reshape(-1,178,1)\n",
    "x_test = x_test.reshape(-1,178,1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "## using a lstm based model\n",
    "model = Sequential()\n",
    "model.add(LSTM(56,input_shape=(45,1),return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(56))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spiritual-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 45, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 45, 1), dtype=tf.float32, name='lstm_4_input'), name='lstm_4_input', description=\"created by layer 'lstm_4_input'\"), but it was called on an input with incompatible shape (10, 178, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 45, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 45, 1), dtype=tf.float32, name='lstm_4_input'), name='lstm_4_input', description=\"created by layer 'lstm_4_input'\"), but it was called on an input with incompatible shape (10, 178, 1).\n",
      "920/920 [==============================] - 166s 178ms/step - loss: 0.3763\n",
      "Epoch 2/60\n",
      "423/920 [============>.................] - ETA: 1:31 - loss: 0.3463"
     ]
    }
   ],
   "source": [
    "hist3 = model.fit(x_train, y_train, epochs=60, batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-invalid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
